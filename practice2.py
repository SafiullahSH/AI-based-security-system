import cv2
import time
import numpy as np

# Load the cascade classifier for face detection
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
# Open the video capture
cap = cv2.VideoCapture(0)

while True:
    # Read the next frame from the video capture
    ret, frame = cap.read()
    mask = np.zeros(frame.shape[:2], dtype=np.uint8)

    frame = cv2.flip(frame, 1)
    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the frame
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    
    bbox_cords = 0
    # Draw rectangles around the faces
    for idx, (x, y, w, h) in enumerate(faces):
        if idx == 0:
            cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)
            bbox_cords = (x,y,w,h)
    
    #cv2.imshow('Faces', frame)

    print(bbox_cords)
    fgModel = np.zeros((1, 65), dtype="float")
    bgModel = np.zeros((1, 65), dtype="float")
    start = time.time()
    (mask, bgModel, fgModel) = cv2.grabCut(frame, mask, bbox_cords, bgModel, fgModel, iterCount=3, mode=cv2.GC_INIT_WITH_RECT)
    end = time.time()
    
    values = (
    ("Definite Background", cv2.GC_BGD),
	("Probable Background", cv2.GC_PR_BGD),
	("Definite Foreground", cv2.GC_FGD),
	("Probable Foreground", cv2.GC_PR_FGD),
    )

    # loop over the possible GrabCut mask values
    for (name, value) in values:
        # construct a mask that for the current value
        print("[INFO] showing mask for '{}'".format(name))
        valueMask = (mask == value).astype("uint8") * 255
	    # display the mask so we can visualize it
        #cv2.imshow(name, valueMask)
        # Display the frame with the faces marked
          

    outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0,1)
    # scale the mask from the range [0, 1] to [0, 255]
    outputMask = (outputMask * 255).astype("uint8")
    # apply a bitwise AND to the image using our mask generated by
    # GrabCut to generate our final output image
    output = cv2.bitwise_and(frame, frame, mask=outputMask)
    
    cv2.imshow("GrabCut Mask", outputMask)
    cv2.imshow("GrabCut Output", output)

    # Break the loop if the 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture
cap.release()
cv2.destroyAllWindows()
